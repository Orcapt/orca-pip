# ğŸ“¦ Lexia Storage SDK - Developer Guide

**Version:** 2.0.0  
**Date:** December 15, 2025  
**Level:** Complete Developer Reference

---

## ğŸ¯ Ù…Ù‚Ø¯Ù…Ù‡

Ø§ÛŒÙ† Ø±Ø§Ù‡Ù†Ù…Ø§ Ù‡Ù…Ù‡ Ú†ÛŒØ²ÛŒ Ú©Ù‡ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Lexia SDK Ù†ÛŒØ§Ø² Ø¯Ø§Ø±ÛŒØ¯ Ø±Ø§ Ù¾ÙˆØ´Ø´ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯. Ø§Ø² Ù†ØµØ¨ Ø³Ø§Ø¯Ù‡ ØªØ§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù¾ÛŒØ´Ø±ÙØªÙ‡.

---

## ğŸ“¥ Ù†ØµØ¨

### Ù†ØµØ¨ Ø§Ø² PyPI (ØªÙˆØµÛŒÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯):

```bash
pip install lexia-sdk
```

### Ù†ØµØ¨ Ø§Ø² GitHub:

```bash
pip install git+https://github.com/your-org/lexia-sdk.git
```

### Ù†ØµØ¨ Ø¯Ø± Ø­Ø§Ù„Øª Development:

```bash
git clone https://github.com/your-org/lexia-sdk.git
cd lexia-sdk
pip install -e .
```

---

## ğŸš€ Ø´Ø±ÙˆØ¹ Ø³Ø±ÛŒØ¹ (Quick Start)

### 1. Ø³Ø§Ø¯Ù‡â€ŒØªØ±ÛŒÙ† Ø§Ø³ØªÙØ§Ø¯Ù‡:

```python
from lexia import LexiaHandler

# Ø§ÛŒØ¬Ø§Ø¯ handler
handler = LexiaHandler(dev_mode=True)  # dev_mode=True Ø¨Ø±Ø§ÛŒ ØªØ³Øª Ù…Ø­Ù„ÛŒ

# Ø´Ø±ÙˆØ¹ session
session = handler.begin(data)

# Ø§Ø±Ø³Ø§Ù„ Ù…Ø­ØªÙˆØ§
session.stream("Ø³Ù„Ø§Ù…! Ø§ÛŒÙ† ÛŒÚ© Ù¾ÛŒØ§Ù… ØªØ³ØªÛŒ Ø§Ø³Øª.")
session.stream("Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´...")

# Ø¨Ø³ØªÙ† session
response = session.close()
print(response)
```

### 2. Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Loading Ùˆ Buttons:

```python
from lexia import LexiaHandler

handler = LexiaHandler(dev_mode=True)
session = handler.begin(data)

# Ù†Ù…Ø§ÛŒØ´ loading
session.loading.start_loading("thinking")

# Ù¾Ø±Ø¯Ø§Ø²Ø´
import time
time.sleep(2)

session.loading.end_loading("thinking")

# Ø§Ø±Ø³Ø§Ù„ Ù†ØªÛŒØ¬Ù‡
session.stream("Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯!")

# Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¯Ú©Ù…Ù‡
session.button.link("Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ø¨ÛŒØ´ØªØ±", "https://example.com")

response = session.close()
```

---

## ğŸ—ï¸ Ù…Ø¹Ù…Ø§Ø±ÛŒ Ùˆ Ø³Ø§Ø®ØªØ§Ø±

### Component Layers:

```
lexia/
â”œâ”€â”€ core/              # Ù‡Ø³ØªÙ‡ Ø§ØµÙ„ÛŒ (Handler, Session)
â”œâ”€â”€ domain/            # Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ùˆ interface Ù‡Ø§
â”œâ”€â”€ services/          # Ø³Ø±ÙˆÛŒØ³â€ŒÙ‡Ø§ÛŒ business logic
â”œâ”€â”€ infrastructure/    # Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ Ø®Ø§Ø±Ø¬ (API, Streaming)
â”œâ”€â”€ patterns/          # Design patterns (Builder, Middleware)
â”œâ”€â”€ observability/     # Metrics, Profiling, Events
â”œâ”€â”€ common/            # Exception, Decorators, Type Guards
â”œâ”€â”€ helpers/           # Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ÛŒ Ú©Ù…Ú©ÛŒ
â”œâ”€â”€ utils/             # ØªÙˆØ§Ø¨Ø¹ utility
â””â”€â”€ web/               # Web framework integration
```

---

## ğŸ“š Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ø§Ù…Ù„

### 1ï¸âƒ£ Ø§ÛŒØ¬Ø§Ø¯ Handler

#### Ø±ÙˆØ´ Ø³Ø§Ø¯Ù‡:

```python
from lexia import LexiaHandler

handler = LexiaHandler(dev_mode=True)
```

#### Ø±ÙˆØ´ Ù¾ÛŒØ´Ø±ÙØªÙ‡ (Ø¨Ø§ Builder Pattern):

```python
from lexia import LexiaBuilder

handler = (
    LexiaBuilder()
    .with_dev_mode(True)
    .with_stream_client(custom_client)
    .build()
)
```

### 2ï¸âƒ£ Ù…Ø¯ÛŒØ±ÛŒØª Session

#### Ø´Ø±ÙˆØ¹ Ùˆ Ù¾Ø§ÛŒØ§Ù† Session:

```python
# Ø´Ø±ÙˆØ¹ session
session = handler.begin(data)

# Ú©Ø§Ø± Ø¨Ø§ session
session.stream("Ù…Ø­ØªÙˆØ§ÛŒ Ø§ÙˆÙ„")
session.stream("Ù…Ø­ØªÙˆØ§ÛŒ Ø¯ÙˆÙ…")

# Ø¨Ø³ØªÙ† session
response = session.close()
```

#### Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Context Manager:

```python
from lexia.patterns import SessionContext

with SessionContext(handler, data) as session:
    session.stream("Ù…Ø­ØªÙˆØ§")
    # session Ø¨Ù‡ Ø·ÙˆØ± Ø®ÙˆØ¯Ú©Ø§Ø± Ø¨Ø³ØªÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯
```

### 3ï¸âƒ£ Streaming Content

#### Stream Ø³Ø§Ø¯Ù‡:

```python
session.stream("Ø§ÛŒÙ† ÛŒÚ© Ù…ØªÙ† Ø³Ø§Ø¯Ù‡ Ø§Ø³Øª.")
```

#### Stream Ú†Ù†Ø¯ Ù…Ø±Ø­Ù„Ù‡â€ŒØ§ÛŒ:

```python
# Ù…Ø±Ø­Ù„Ù‡ 1
session.stream("Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§...")

# Ù¾Ø±Ø¯Ø§Ø²Ø´
process_data()

# Ù…Ø±Ø­Ù„Ù‡ 2
session.stream("\n\nÙ†ØªØ§ÛŒØ¬:")
for result in results:
    session.stream(f"\n- {result}")
```

#### Stream Ø¨Ø§ Chunking:

```python
# Ø¨Ø±Ø§ÛŒ Ù…Ø­ØªÙˆØ§ÛŒ Ø·ÙˆÙ„Ø§Ù†ÛŒ
long_text = generate_long_response()

# Ø¨Ù‡ ØµÙˆØ±Øª Ø®ÙˆØ¯Ú©Ø§Ø± chunk Ù…ÛŒâ€ŒØ´ÙˆØ¯
session.stream(long_text)
```

### 4ï¸âƒ£ Loading Markers

```python
from lexia.config import LoadingKind

# Ø§Ù†ÙˆØ§Ø¹ loading
session.loading.start_loading("thinking")     # Ø¯Ø± Ø­Ø§Ù„ ÙÚ©Ø± Ú©Ø±Ø¯Ù†
session.loading.start_loading("searching")    # Ø¯Ø± Ø­Ø§Ù„ Ø¬Ø³ØªØ¬Ùˆ
session.loading.start_loading("coding")       # Ø¯Ø± Ø­Ø§Ù„ Ú©Ø¯ Ù†ÙˆÛŒØ³ÛŒ
session.loading.start_loading("analyzing")    # Ø¯Ø± Ø­Ø§Ù„ ØªØ­Ù„ÛŒÙ„
session.loading.start_loading("generating")   # Ø¯Ø± Ø­Ø§Ù„ ØªÙˆÙ„ÛŒØ¯

# Ø§Ù†Ø¬Ø§Ù… Ú©Ø§Ø±
do_heavy_work()

# Ù¾Ø§ÛŒØ§Ù† loading
session.loading.end_loading("thinking")
```

### 5ï¸âƒ£ Buttons

#### Ø¯Ú©Ù…Ù‡ Link:

```python
session.button.link(
    label="Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ø³Ø§ÛŒØª",
    url="https://example.com",
    row=1,
    color="primary"
)
```

#### Ø¯Ú©Ù…Ù‡ Action:

```python
session.button.action(
    label="ØªØ§ÛŒÛŒØ¯",
    action_id="confirm_action",
    row=1,
    color="success"
)
```

#### Ú†Ù†Ø¯ Ø¯Ú©Ù…Ù‡ Ù‡Ù…Ø²Ù…Ø§Ù†:

```python
# Ø´Ø±ÙˆØ¹ batch
session.button.buttons_begin(default_row=1)

# Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¯Ú©Ù…Ù‡â€ŒÙ‡Ø§
session.button.buttons_add_link("Ú¯Ø²ÛŒÙ†Ù‡ 1", "https://example.com/1")
session.button.buttons_add_link("Ú¯Ø²ÛŒÙ†Ù‡ 2", "https://example.com/2")
session.button.buttons_add_action("Ø§Ù†Ø¬Ø§Ù… Ø¹Ù…Ù„ÛŒØ§Øª", "do_action")

# Ù¾Ø§ÛŒØ§Ù† batch
session.button.buttons_end()
```

#### Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Helper Method:

```python
session.button.buttons(
    {"type": "link", "label": "Ù„ÛŒÙ†Ú© 1", "url": "https://example.com"},
    {"type": "action", "label": "Ø¹Ù…Ù„ÛŒØ§Øª", "action_id": "action_1"},
    defaults={"row": 1, "color": "primary"}
)
```

### 6ï¸âƒ£ Images

```python
# Ø§Ø±Ø³Ø§Ù„ ØªØµÙˆÛŒØ±
session.image.image("https://example.com/image.jpg")

# ÛŒØ§
session.pass_image("https://example.com/image.jpg")
```

### 7ï¸âƒ£ Tracing

```python
# Ø´Ø±ÙˆØ¹ trace
session.tracing.begin("Ø¯Ø± Ø­Ø§Ù„ ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ API...", visibility="all")

# Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù„Ø§Ú¯
session.tracing.append("Ù¾Ø§Ø³Ø® Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯")
session.tracing.append("Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´...")

# Ù¾Ø§ÛŒØ§Ù† trace
session.tracing.end("Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªÙ…Ø§Ù… Ø´Ø¯")
```

### 8ï¸âƒ£ Usage Tracking

```python
from lexia.config import TokenType

# Ø«Ø¨Øª token usage
session.usage.track(
    tokens=1500,
    token_type="prompt",
    cost="0.003",
    label="GPT-4"
)

session.usage.track(
    tokens=500,
    token_type="completion",
    cost="0.001",
    label="GPT-4"
)
```

### 9ï¸âƒ£ Error Handling

```python
try:
    # Ú©Ø§Ø± Ø§ØµÙ„ÛŒ
    result = risky_operation()
    session.stream(f"Ù†ØªÛŒØ¬Ù‡: {result}")

except Exception as e:
    # Ø§Ø±Ø³Ø§Ù„ Ø®Ø·Ø§ Ø¨Ù‡ Ú©Ø§Ø±Ø¨Ø±
    session.error(
        error_message="Ù…ØªØ§Ø³ÙØ§Ù†Ù‡ Ø®Ø·Ø§ÛŒÛŒ Ø±Ø® Ø¯Ø§Ø¯",
        exception=e,
        trace=traceback.format_exc()
    )
```

---

## ğŸ¨ Design Patterns

### 1ï¸âƒ£ Builder Pattern

```python
from lexia import LexiaBuilder

handler = (
    LexiaBuilder()
    .with_dev_mode(True)
    .with_stream_client(my_client)
    .build()
)
```

### 2ï¸âƒ£ Context Managers

```python
from lexia.patterns import SessionContext, timed_operation

# Session Ø¨Ø§ cleanup Ø®ÙˆØ¯Ú©Ø§Ø±
with SessionContext(handler, data) as session:
    session.stream("Ù…Ø­ØªÙˆØ§")

# Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ø²Ù…Ø§Ù†
with timed_operation("database_query"):
    results = db.query(...)
```

### 3ï¸âƒ£ Middleware Pattern

```python
from lexia.patterns import (
    MiddlewareChain,
    LoggingMiddleware,
    ValidationMiddleware,
)

# Ø³Ø§Ø®Øª pipeline
chain = MiddlewareChain()
chain.add(LoggingMiddleware())

def validate(data):
    return 'user_id' in data

chain.add(ValidationMiddleware(validate))

# Ù¾Ø±Ø¯Ø§Ø²Ø´
processed = chain.process_request(request_data)
```

---

## ğŸ”­ Observability

### 1ï¸âƒ£ Metrics

```python
from lexia import get_metrics_collector

collector = get_metrics_collector()

# Counter
requests = collector.counter("api_requests")
requests.inc()

# Gauge
active_users = collector.gauge("active_users")
active_users.set(150)

# Histogram
response_time = collector.histogram("response_time_seconds")
response_time.observe(0.234)

# Ø¯Ø±ÛŒØ§ÙØª metrics
all_metrics = collector.get_metrics()
```

### 2ï¸âƒ£ Performance Profiling

```python
from lexia import profile

@profile(sort_by='time', limit=10)
def expensive_function():
    # Ú©Ø¯ Ù¾ÛŒÚ†ÛŒØ¯Ù‡
    pass

# ÛŒØ§ Ø¨Ø§ context manager
from lexia.observability import Profiler

with Profiler() as prof:
    expensive_operation()
prof.print_stats()
```

### 3ï¸âƒ£ Event System

```python
from lexia import get_event_bus

bus = get_event_bus()

# Subscribe
def on_request(event):
    print(f"Request: {event.data}")

bus.subscribe("api.request", on_request)

# Publish
bus.publish("api.request", {
    "endpoint": "/api/users",
    "method": "GET"
})
```

### 4ï¸âƒ£ System Monitoring

```python
from lexia import SystemMonitor

monitor = SystemMonitor()

# System stats
stats = monitor.get_system_stats()
print(f"CPU: {stats['cpu_percent']}%")
print(f"Memory: {stats['memory_percent']}%")

# Health checks
def check_db():
    # Ø¨Ø±Ø±Ø³ÛŒ Ø¯ÛŒØªØ§Ø¨ÛŒØ³
    return True, "DB OK", {}

monitor.add_health_check("database", check_db, critical=True)

health = monitor.check_health()
print(f"Healthy: {health['healthy']}")
```

---

## ğŸ›¡ï¸ Error Handling

### Custom Exceptions

```python
from lexia import (
    LexiaException,
    ConfigurationError,
    ValidationError,
    StreamError,
    APIError,
)

try:
    # Ú©Ø§Ø± Ø§ØµÙ„ÛŒ
    pass
except ValidationError as e:
    # Ø®Ø·Ø§ÛŒ validation
    print(f"Validation error: {e}")
except APIError as e:
    # Ø®Ø·Ø§ÛŒ API
    print(f"API error: {e}")
except LexiaException as e:
    # Ù‡Ø± Ø®Ø·Ø§ÛŒ Ø¯ÛŒÚ¯Ø± Ø§Ø² Lexia
    print(f"Lexia error: {e}")
```

### Decorators

```python
from lexia import retry, log_execution, handle_errors

@retry(max_attempts=3, delay=1.0)
@log_execution
def unreliable_api_call():
    # ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ API Ú©Ù‡ Ù…Ù…Ú©Ù† Ø§Ø³Øª fail Ø´ÙˆØ¯
    return api.call()

@handle_errors
def risky_operation():
    # Ø¹Ù…Ù„ÛŒØ§Øª Ø®Ø·Ø±Ù†Ø§Ú©
    pass
```

---

## ğŸŒ Production Usage

### 1ï¸âƒ£ Configuration

```python
from lexia import LexiaHandler

# Production mode
handler = LexiaHandler(
    dev_mode=False,  # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Centrifugo ÙˆØ§Ù‚Ø¹ÛŒ
    # Ø³Ø§ÛŒØ± ØªÙ†Ø¸ÛŒÙ…Ø§Øª...
)
```

### 2ï¸âƒ£ Ø¨Ø§ Centrifugo

```python
# data Ø¨Ø§ÛŒØ¯ Ø´Ø§Ù…Ù„ Ø§ÛŒÙ† ÙÛŒÙ„Ø¯Ù‡Ø§ Ø¨Ø§Ø´Ø¯:
data = {
    'stream_url': 'https://your-centrifugo-server.com',
    'stream_token': 'your-token',
    'channel': 'channel-name',
    'uuid': 'unique-message-id',
    'thread_id': 'thread-id',
    # Ø³Ø§ÛŒØ± ÙÛŒÙ„Ø¯Ù‡Ø§...
}

handler = LexiaHandler(dev_mode=False)
session = handler.begin(data)
```

### 3ï¸âƒ£ Ø¨Ø§ API Client

```python
# Ø¨Ø±Ø§ÛŒ usage tracking Ùˆ Ø³Ø§ÛŒØ± API calls
data = {
    'api_url': 'https://your-api.com',
    'api_token': 'your-api-token',
    # ...
}
```

---

## ğŸ“Š Ù…Ø«Ø§Ù„ Ú©Ø§Ù…Ù„ Production

```python
from lexia import LexiaHandler, get_metrics_collector
from lexia.patterns import timed_operation
import logging

logger = logging.getLogger(__name__)

def handle_user_request(data):
    """
    Handler Ø§ØµÙ„ÛŒ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ú©Ø§Ø±Ø¨Ø±.
    """
    # Setup
    handler = LexiaHandler(dev_mode=False)
    collector = get_metrics_collector()
    requests_counter = collector.counter("user_requests")

    try:
        # Ø´Ø±ÙˆØ¹ session
        session = handler.begin(data)
        requests_counter.inc()

        # Loading
        session.loading.start_loading("thinking")

        # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ø§ timing
        with timed_operation("ai_processing"):
            # ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ AI
            result = call_ai_model(data['prompt'])

        session.loading.end_loading("thinking")

        # Ø§Ø±Ø³Ø§Ù„ Ù†ØªÛŒØ¬Ù‡
        session.stream(result['text'])

        # Usage tracking
        session.usage.track(
            tokens=result['prompt_tokens'],
            token_type="prompt",
            cost=calculate_cost(result['prompt_tokens'], "prompt")
        )
        session.usage.track(
            tokens=result['completion_tokens'],
            token_type="completion",
            cost=calculate_cost(result['completion_tokens'], "completion")
        )

        # Ø¯Ú©Ù…Ù‡â€ŒÙ‡Ø§
        if result.get('has_more'):
            session.button.link("Ø§Ø¯Ø§Ù…Ù‡ Ù…Ø·Ù„Ø¨", result['more_url'])

        # Ø¨Ø³ØªÙ† session
        response = session.close(usage_info=result.get('usage'))

        logger.info(f"Request processed successfully: {data['uuid']}")
        return response

    except Exception as e:
        logger.error(f"Error processing request: {e}", exc_info=True)

        # Ø§Ø±Ø³Ø§Ù„ Ø®Ø·Ø§ Ø¨Ù‡ Ú©Ø§Ø±Ø¨Ø±
        if 'session' in locals():
            session.error(
                error_message="Ù…ØªØ§Ø³ÙØ§Ù†Ù‡ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø±Ø® Ø¯Ø§Ø¯. Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯.",
                exception=e
            )

        raise


def call_ai_model(prompt):
    """ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ù…Ø¯Ù„ AI"""
    # Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ
    pass

def calculate_cost(tokens, token_type):
    """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù‡Ø²ÛŒÙ†Ù‡"""
    rates = {
        "prompt": 0.00002,      # $0.02 per 1K tokens
        "completion": 0.00004,  # $0.04 per 1K tokens
    }
    return tokens * rates.get(token_type, 0)
```

---

## ğŸ§ª Testing

### Unit Testing

```python
import unittest
from lexia import LexiaHandler

class TestLexiaHandler(unittest.TestCase):
    def setUp(self):
        self.handler = LexiaHandler(dev_mode=True)
        self.test_data = {
            'channel': 'test-channel',
            'uuid': 'test-uuid',
            'thread_id': 'test-thread',
        }

    def test_basic_streaming(self):
        session = self.handler.begin(self.test_data)
        session.stream("Test message")
        response = session.close()

        self.assertIn('status', response)
        self.assertEqual(response['status'], 'success')

    def test_loading_markers(self):
        session = self.handler.begin(self.test_data)
        session.loading.start_loading("thinking")
        session.loading.end_loading("thinking")
        response = session.close()

        self.assertEqual(response['status'], 'success')
```

### Integration Testing

```python
def test_full_workflow():
    """ØªØ³Øª workflow Ú©Ø§Ù…Ù„"""
    handler = LexiaHandler(dev_mode=True)

    data = {
        'channel': 'test-channel',
        'uuid': 'test-uuid',
        'thread_id': 'test-thread',
    }

    session = handler.begin(data)

    # Loading
    session.loading.start_loading("thinking")

    # Stream
    session.stream("Processing...")

    # Loading end
    session.loading.end_loading("thinking")

    # Result
    session.stream("Done!")

    # Buttons
    session.button.link("View", "https://example.com")

    # Close
    response = session.close()

    assert response['status'] == 'success'
```

---

## ğŸ“– Best Practices

### 1ï¸âƒ£ Ù‡Ù…ÛŒØ´Ù‡ Ø§Ø² Context Manager Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯:

```python
# âœ… Good
with SessionContext(handler, data) as session:
    session.stream("Ù…Ø­ØªÙˆØ§")

# âŒ Bad (Ù…Ù…Ú©Ù† Ø§Ø³Øª session Ø¨Ø³ØªÙ‡ Ù†Ø´ÙˆØ¯)
session = handler.begin(data)
session.stream("Ù…Ø­ØªÙˆØ§")
# ÙØ±Ø§Ù…ÙˆØ´ Ú©Ø±Ø¯Ù† close()
```

### 2ï¸âƒ£ Error Handling Ù…Ù†Ø§Ø³Ø¨:

```python
# âœ… Good
try:
    session.stream(risky_operation())
except Exception as e:
    session.error("Ø®Ø·Ø§ Ø±Ø® Ø¯Ø§Ø¯", exception=e)

# âŒ Bad (Ø®Ø·Ø§ Ø±Ø§ ignore Ù…ÛŒâ€ŒÚ©Ù†Ø¯)
try:
    session.stream(risky_operation())
except:
    pass
```

### 3ï¸âƒ£ Loading Ø¨Ø±Ø§ÛŒ Ø¹Ù…Ù„ÛŒØ§Øª Ø·ÙˆÙ„Ø§Ù†ÛŒ:

```python
# âœ… Good
session.loading.start_loading("thinking")
result = long_operation()
session.loading.end_loading("thinking")

# âŒ Bad (Ú©Ø§Ø±Ø¨Ø± Ù…Ù†ØªØ¸Ø± Ù…ÛŒâ€ŒÙ…Ø§Ù†Ø¯ Ø¨Ø¯ÙˆÙ† feedback)
result = long_operation()
```

### 4ï¸âƒ£ Usage Tracking:

```python
# âœ… Good
session.usage.track(tokens=1500, token_type="prompt", cost="0.03")

# âŒ Bad (token usage track Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯)
# Ù‡ÛŒÚ† tracking Ù†Ø¯Ø§Ø±ÛŒÙ…
```

### 5ï¸âƒ£ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Observability:

```python
# âœ… Good
from lexia import get_metrics_collector

collector = get_metrics_collector()
counter = collector.counter("requests")
counter.inc()

# âŒ Bad (metrics Ù†Ø¯Ø§Ø±ÛŒÙ…)
# ÙÙ‚Ø· logging
```

---

## ğŸ”§ Troubleshooting

### Ù…Ø´Ú©Ù„: Session Ø¨Ø³ØªÙ‡ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯

```python
# Ø±Ø§Ù‡ Ø­Ù„: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Context Manager
with SessionContext(handler, data) as session:
    session.stream("Ù…Ø­ØªÙˆØ§")
```

### Ù…Ø´Ú©Ù„: Ø®Ø·Ø§ÛŒ Connection

```python
# Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯:
# 1. dev_mode ØµØ­ÛŒØ­ Ø§Ø³ØªØŸ
# 2. stream_url Ùˆ stream_token Ø¯Ø±Ø³Øª Ù‡Ø³ØªÙ†Ø¯ØŸ
# 3. network connectivity

handler = LexiaHandler(dev_mode=True)  # Ø¨Ø±Ø§ÛŒ ØªØ³Øª Ù…Ø­Ù„ÛŒ
```

### Ù…Ø´Ú©Ù„: Performance Ù¾Ø§ÛŒÛŒÙ†

```python
# Ø±Ø§Ù‡ Ø­Ù„: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Profiling
from lexia import profile

@profile(sort_by='cumulative')
def slow_function():
    # Ú©Ø¯ Ø´Ù…Ø§
    pass
```

---

## ğŸ“š Ù…Ù†Ø§Ø¨Ø¹ Ø¨ÛŒØ´ØªØ±

- [Architecture Guide](./ARCHITECTURE.md) - Ù…Ø¹Ù…Ø§Ø±ÛŒ Ú©Ø§Ù…Ù„
- [Examples](./examples/) - Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ù…Ù„
- [API Reference](./API_REFERENCE.md) - Ù…Ø±Ø¬Ø¹ Ú©Ø§Ù…Ù„ API
- [Lambda Deploy Guide](./LAMBDA_DEPLOY_GUIDE.md) - Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ deploy

---

## ğŸ’¬ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ

- **Issues:** https://github.com/your-org/lexia-sdk/issues
- **Discussions:** https://github.com/your-org/lexia-sdk/discussions
- **Email:** support@your-org.com

---

**Ø§ÛŒÙ† Ø±Ø§Ù‡Ù†Ù…Ø§ Ø¨Ù‡ Ø·ÙˆØ± Ù…Ø¯Ø§ÙˆÙ… Ø¨Ù‡â€ŒØ±ÙˆØ² Ù…ÛŒâ€ŒØ´ÙˆØ¯. Ø¢Ø®Ø±ÛŒÙ† Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ: December 15, 2025**
